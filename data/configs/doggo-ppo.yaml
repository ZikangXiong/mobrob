# environment parameters
env_name: doggo
time_limit: 1000
n_envs: 6
vec_env_type: subproc
enable_gui: False

# parameters of stable-baselines3 PPO algorithm
ppo_kwargs: 
  policy: MlpPolicy
  n_steps: 1000
  batch_size: 200
  n_epochs: 10
  ent_coef: 0.05
  gae_lambda: 0.5
  verbose: 1
  device: cpu

# total simulation steps
total_timesteps: 8_000_000